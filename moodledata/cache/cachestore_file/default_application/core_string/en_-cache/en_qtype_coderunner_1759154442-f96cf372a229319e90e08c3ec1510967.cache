a:530:{s:7:"aborted";s:33:"Testing was aborted due to error.";s:14:"ace_aria_label";s:35:"Code editor - Enter your code here.";s:31:"ace_gapfillerui_ui_source_descr";s:132:""globalextra" to take the code to display from the globalextra field or "test0" to take it from the testcode field of the first test";s:15:"ace_ui_notready";s:42:"Ace editor not ready. Perhaps reload page?";s:34:"aceui_auto_switch_light_dark_descr";s:86:"Allow a browser or OS preference for dark themes to override a preset Ace light theme.";s:31:"aceui_live_autocompletion_descr";s:49:"Enable the Ace editor's live autocompletion mode.";s:21:"aceui_font_size_descr";s:21:"Ace editor font size.";s:34:"aceui_import_from_scratchpad_descr";s:231:"True to allow the Ace editor to receive the JSON-format answer used by the scratchpad UI and extract the answer code from it. Facilitates switching UIs. Leave true unless you want Ace to edit JSON objects with an "answer_code" key.";s:17:"aceui_theme_descr";s:173:"Ace editor theme. Default is the light theme "textmate". An alternative dark theme is "tomorrow_night". Light theme be overridden by user preferences - see auto_switch_dark.";s:16:"addingcoderunner";s:32:"Adding a new CodeRunner Question";s:10:"ajax_error";s:36:"*** AJAX ERROR. DON'T SAVE THIS! ***";s:5:"allok";s:18:"Passed all tests! ";s:9:"allornone";s:64:"Test code must be provided either for all testcases or for none.";s:12:"allornothing";s:22:"All-or-nothing grading";s:17:"allornothing_help";s:458:"If 'All-or-nothing' is checked, all test cases must be satisfied for the submission to earn any marks. Otherwise, the mark is obtained by summing the marks for all the test cases that pass and expressing this as a fraction of the maximum possible mark.

The per-test-case marks can be specified only if the all-or-nothing checkbox is unchecked.

If using a template grader that awards part marks to test cases, 'All-or-nothing' should generally be unchecked.";s:16:"allowattachments";s:17:"Allow attachments";s:21:"allowattachments_help";s:526:"Whether to allow students to add attachments to their submissions and, if so, how many. Attachments are copied into the runtime working directory and a comma-separated list of the names of the attachments is provided  to the template in the Twig variable {{ ATTACHMENTS }}. Warning: allowing attachments could have performance or disk-space implications for the Moodle and Jobe servers with large classes and/or large attachments. The Moodle server, and Jobe servers prior to February 2019, store all attachments indefinitely.";s:16:"allowedfilenames";s:18:"Allowed file names";s:21:"allowedfilenamesregex";s:39:"Allowed file names (regular expression)";s:21:"allowedfilenames_help";s:617:"All uploaded file names must match the given PHP (Perl) regular expression, if non empty. For example, use '.+\\.cpp' to allow any C++ file or '(?!Prog)\\.java' to allow any Java file except 'Prog.java'. Additionally, filenames must contain only alphanumeric characters plus underscore, hyphen and period, must not start with double-underscore ('\_\_') and must not conflict with any of the support file names. The Description is a text message shown to the student to explain what file(s) are expected. Leave empty to display the regular expression itself. Leave both empty to bypass the regular expression checking.";s:19:"allowmultiplestdins";s:21:"Allow multiple stdins";s:6:"answer";s:6:"Answer";s:12:"answerprompt";s:7:"Answer:";s:11:"answer_help";s:271:"A sample answer can be entered here and used for checking by the question author and optionally shown to students during review. It is also used by the bulk tester script. The correctness of a non-empty answer is checked when saving unless 'Validate on save' is unchecked";s:15:"answerunchanged";s:47:"You must complete or edit the preloaded answer.";s:14:"answerrequired";s:33:"Please provide a non-empty answer";s:14:"answertooshort";s:51:"Answer too short. Must be at least {$a} characters.";s:14:"atleastonetest";s:58:"You must provide at least one test case for this question.";s:12:"ace-language";s:12:"Ace language";s:22:"advanced_customisation";s:22:"Advanced customisation";s:15:"answerbox_group";s:10:"Answer box";s:14:"answerboxlines";s:4:"Rows";s:20:"answerbox_group_help";s:274:"Set the number of rows to allocate for the answer box. This sets the minimum height of the User Interface element (e.g. Ace) that controls the answer box. The width is set to fit the window. If the answer overflows the box vertically or horizontally, scrollbars will appear.";s:13:"answerpreload";s:18:"Answer box preload";s:18:"answerpreload_help";s:67:"Text supplied here will be preloaded into the student's answer box.";s:11:"asolutionis";s:37:"Show/hide question author's solution:";s:17:"attachmentoptions";s:18:"Attachment options";s:19:"attachmentsoptional";s:24:"Attachments are optional";s:19:"attachmentsrequired";s:19:"Require attachments";s:24:"attachmentsrequired_help";s:93:"This option specifies the minimum number of attachments required for a response to be graded.";s:22:"autotagbycategorytitle";s:30:"CodeRunner autotag by category";s:27:"autotagbycategoryindextitle";s:30:"CodeRunner question autotagger";s:16:"badacelangstring";s:23:"Bad Ace-language string";s:10:"badcputime";s:73:"CPU time limit must be left blank or must be an integer greater than zero";s:13:"bad_dotdotdot";s:71:"Misuse of '...'. Must be at end, after two increasing numeric penalties";s:16:"bademptyprecheck";s:53:"Precheck failed with the following unexpected output.";s:18:"bad_empty_splitter";s:62:"Test splitter cannot be empty when using a combinator template";s:17:"badfilenamesregex";s:26:"Invalid regular expression";s:8:"badfiles";s:29:"Disallowed file name(s): {$a}";s:11:"badjsonfunc";s:39:"Unknown JSON embedded func ({$a->func})";s:7:"badjson";s:64:"Bad JSON output from combinator grader. Output was: {$a->output}";s:11:"badmemlimit";s:72:"Memory limit must either be left blank or must be a non-negative integer";s:22:"bad_new_prototype_name";s:46:"Illegal name for new prototype: already in use";s:12:"badpenalties";s:78:"Penalty regime must be a comma separated list of numbers in the range [0, 100]";s:11:"badquestion";s:17:"Error in question";s:15:"badrandomintarg";s:40:"Bad argument to JSON @randomint function";s:16:"badrandompickarg";s:40:"Bad argument to JSON @randompic function";s:16:"badsandboxparams";s:74:"'Other' field (sandbox params) must be either blank or a valid JSON record";s:17:"badtemplateparams";s:115:"Template parameters must evaluate to blank or a valid JSON record. Got: <pre class="templateparamserror">{$a}</pre>";s:11:"baduiparams";s:51:"UI parameters must be blank or a valid JSON record.";s:16:"brokencombinator";s:106:"Expected {$a->numtests} test results, got {$a->numresults}. Perhaps excessive output or error in question?";s:20:"brokentemplategrader";s:120:"Bad output from grader: {$a->output}. Your program execution may have aborted (e.g. a timeout or memory limit exceeded).";s:18:"bulkquestiontester";s:235:"The <a href="{$a->link}">bulk tester script</a> tests that the sample answers for all questions in the current context are marked right. Useful only once some questions with sample answers have been added; the initial install has none.";s:20:"bulktestallincontext";s:8:"Test all";s:24:"bulktestcontinuefromhere";s:39:"Run again or resume, starting from here";s:18:"bulktestindextitle";s:23:"CodeRunner bulk testing";s:11:"bulktestrun";s:81:"Run all the question tests for all the questions in the system (slow, admin only)";s:13:"bulktesttitle";s:25:"Testing questions in {$a}";s:16:"bulktestalltitle";s:30:"Testing ALL questions in site.";s:18:"cannotrunprototype";s:123:"This is a prototype and cannot be run. If you wish to use this prototype, create a new question and set this question type.";s:20:"coderunnercategories";s:36:"Categories with CodeRunner questions";s:18:"coderunnercontexts";s:34:"Contexts with CodeRunner questions";s:10:"coderunner";s:12:"Program Code";s:34:"coderunner_install_testsuite_title";s:42:"A test suite for CodeRunner sample answers";s:39:"coderunner_install_testsuite_title_desc";s:128:"The <a href="{$a->link}">sample-answer-test script</a> verifies that the questions with sample answers are performing correctly.";s:34:"coderunner_install_testsuite_intro";s:105:"This page allows you to test that the CodeRunner questions with sample answers are functioning correctly.";s:37:"coderunner_install_testsuite_failures";s:17:"Tests that failed";s:37:"coderunner_install_testsuite_noanswer";s:32:"Questions without sample answers";s:26:"coderunner:sandboxwsaccess";s:49:"Allow access to the Jobe sandbox via web services";s:30:"coderunner:viewhiddentestcases";s:45:"See hidden testcases when reviewing questions";s:15:"coderunner_help";s:203:"In response to a question, which is a specification for a program fragment, function or whole program, the respondent enters source code in a specified computer language that satisfies the specification.";s:15:"coderunner_link";s:24:"question/type/coderunner";s:24:"coderunner_question_type";s:26:"CodeRunner question type: ";s:18:"coderunnersettings";s:19:"CodeRunner settings";s:17:"coderunnersummary";s:107:"Answer is program code that is executed in the context of a set of test cases to determine its correctness.";s:14:"coderunnertype";s:13:"Question type";s:19:"coderunnertype_help";s:143:"Select the programming language and question type. Once a type has been selected, details can be seen in the Question type details panel below.";s:20:"coderunnerwssettings";s:28:"Sandbox web-service settings";s:14:"columncontrols";s:12:"Result table";s:19:"columncontrols_help";s:108:"The checkboxes select which columns of the results table should be displayed to the student after submission";s:15:"confirm_proceed";s:100:"If you save this question with 'Customise' unchecked, any customisations made will be lost. Proceed?";s:12:"confirmreset";s:88:"Discard all your work on this question and reset answer box to original preloaded value?";s:15:"corruptuiparams";s:86:"The UI parameters for this question or its prototype are broken. Proceed with caution.";s:7:"cputime";s:16:"TimeLimit (secs)";s:21:"customisationcontrols";s:13:"Customisation";s:9:"customise";s:9:"Customise";s:13:"customisation";s:13:"Customisation";s:9:"datafiles";s:13:"Support files";s:14:"datafiles_help";s:176:"Any files uploaded here will be added to the working directory when the expanded template program is executed. This allows large data or support files to be conveniently added.";s:22:"default_penalty_regime";s:22:"Default penalty regime";s:27:"default_penalty_regime_desc";s:190:"The default penalty regime to apply to new questions, consisting of a comma separated list of penalty percentages, optionally ending in ", ..." to signify an on-going arithmetic progression.";s:7:"display";s:7:"Display";s:20:"downloadquizattempts";s:22:"Download quiz attempts";s:24:"downloadquizattemptshelp";s:315:"Click the appropriate course and/or download button
        for the course and quiz you wish to download. Numbers in parentheses
        after courses are the number of quizzes in the course with at least
        one submission. The numbers in parentheses after the quiz name
        are the numbers of submissions.";s:18:"duplicateprototype";s:202:"This question was defined to be of type '{$a->crtype}' but the prototype is non-unique in the following questions: {$a->outputstring} Please remove all but one instance, or select another question type.";s:17:"editingcoderunner";s:29:"Editing a CodeRunner Question";s:24:"empty_new_prototype_name";s:38:"New question type name cannot be empty";s:18:"emptypenaltyregime";s:50:"Penalty regime must be defined (since version 3.1)";s:20:"emptysandboxlanguage";s:59:"Sandbox language cannot be empty when creating a prototype.";s:6:"enable";s:6:"Enable";s:16:"enablecombinator";s:17:"Enable combinator";s:17:"enable_diff_check";s:32:"Enable 'Show differences' button";s:22:"enable_diff_check_desc";s:117:"Present students with a 'Show differences' button if their answer is wrong and an exact-match validator is being used";s:19:"enable_sandbox_desc";s:67:"Permit use of the specified sandbox for running student submissions";s:15:"enter_to_submit";s:24:"Press Enter to submit...";s:14:"equalitygrader";s:11:"Exact match";s:23:"error_loading_prototype";s:66:"Error loading prototype. Network problems or server down, perhaps?";s:22:"error_loading_ui_descr";s:71:"Error loading UI description. Network problems or server down, perhaps?";s:11:"erroroninit";s:61:"**** ERROR WHEN INITIALISING QUESTION ****<br>{$a->error}<br>";s:14:"errorstring-ok";s:2:"OK";s:21:"errorstring-autherror";s:27:"Unauthorised to use sandbox";s:23:"errorstring-blocked-url";s:75:"The URL is blocked. Check the Jobe URL and Moodle's HTTP security settings.";s:26:"errorstring-duplicate-name";s:76:"Rename class name; this name conflicts with support files for this question.";s:19:"errorstring-jobe400";s:32:"Error from Jobe sandbox server: ";s:23:"errorstring-jobe-failed";s:28:"Jobe server request failed. ";s:20:"errorstring-overload";s:71:"Job could not be run due to server overload. Perhaps try again shortly?";s:25:"errorstring-pastenotfound";s:37:"Requesting status of non-existent job";s:23:"errorstring-wronglangid";s:31:"Non-existent language requested";s:24:"errorstring-accessdenied";s:24:"Access to sandbox denied";s:35:"errorstring-submissionlimitexceeded";s:32:"Sandbox submission limit reached";s:28:"errorstring-submissionfailed";s:28:"Submission to sandbox failed";s:19:"errorstring-unknown";s:116:"Unexpected error while executing your code. The sandbox server may be down or overloaded. Perhaps try again shortly?";s:19:"error_access_denied";s:28:"Sandbox server access denied";s:22:"error_excessive_output";s:16:"Excessive output";s:17:"error_json_params";s:41:"Params set are not in correct JSON format";s:18:"error_jobe_unknown";s:30:"Unknown error from Jobe server";s:18:"error_memory_limit";s:21:"Memory limit exceeded";s:29:"error_sandbox_server_overload";s:20:"Jobe server overload";s:30:"error_submission_limit_reached";s:37:"Jobe sandbox submission limit reached";s:13:"error_timeout";s:19:"Time limit exceeded";s:22:"error_unknown_language";s:26:"Unknown language requested";s:21:"error_unknown_runtime";s:21:"Unknown runtime error";s:27:"event_sandboxwebserviceexec";s:15:"CR sandbox exec";s:32:"event_sandboxwebserviceexec_desc";s:58:"A job was executed via the CodeRunner sandbox web service.";s:15:"exit_fullscreen";s:16:"Exit full screen";s:6:"expand";s:6:"Expand";s:11:"expandtitle";s:24:"Show question categories";s:8:"expected";s:15:"Expected output";s:14:"expectedcolhdr";s:8:"Expected";s:13:"expected_help";s:77:"The expected output from the test. Seen by the template as {{TEST.expected}}.";s:18:"exportthisquestion";s:20:"Export this question";s:23:"exportthisquestion_help";s:220:"This will create a Moodle XML export file containing just this one question. One example of when this is useful if you think this question demonstrates a bug in CodeRunner that you would like to report to the developers.";s:5:"extra";s:19:"Extra template data";s:10:"extra_help";s:87:"A sometimes-useful extra text field for use by the template, accessed as {{TEST.extra}}";s:19:"extractcodefromjson";s:24:"Ace/Scratchpad compliant";s:4:"fail";s:4:"Fail";s:5:"fails";s:8:"failures";s:12:"failedhidden";s:42:"Your code failed one or more hidden tests.";s:12:"failedntests";s:30:"Failed {$a->numerrors} test(s)";s:13:"failedtesting";s:15:"Failed testing.";s:8:"feedback";s:8:"Feedback";s:13:"feedback_quiz";s:11:"Set by quiz";s:13:"feedback_show";s:10:"Force show";s:13:"feedback_hide";s:10:"Force hide";s:13:"feedback_help";s:230:"Choose 'Set by quiz' to allow the quiz's review options (specifically the
'Specific feedback' setting) to control display of the result table, 'Force show' to show the result table regardless and 'Force hide' to hide it regardless";s:10:"fileheader";s:13:"Support files";s:16:"filenamesexplain";s:11:"Description";s:14:"filenamesregex";s:18:"Regular expression";s:16:"filloutoneanswer";s:158:"You must enter source code that satisfies the specification. The code you enter will be executed to determine its correctness and a grade awarded accordingly.";s:12:"firstfailure";s:29:"First failing test case: {$a}";s:10:"forexample";s:11:"For example";s:10:"fullscreen";s:11:"Full screen";s:28:"gapfillerui_delimiters_descr";s:75:"A 2-element array of the strings used to open and close the gap description";s:27:"gapfillerui_ui_source_descr";s:132:""globalextra" to take the HTML to display from the globalextra field or "test0" to take it from the testcode field of the first test";s:36:"gapfillerui_sync_interval_secs_descr";s:123:"The time interval in seconds between calls to sync the UI contents back to the question answer. 0 for no such auto-syncing.";s:6:"giveup";s:11:"Stop button";s:20:"giveup_aftermaxmarks";s:38:"Available once mark cannot be improved";s:13:"giveup_always";s:16:"Always available";s:11:"giveup_help";s:285:"If this option is enabled, students will see a button to stop interacting with the question, and instead display the general feedback.

The 'Stop and read final feedback' can be shown from the start, or only once the student can no longer improve their mark, due to the penalty regime.";s:12:"giveup_never";s:15:"Never available";s:11:"globalextra";s:12:"Global extra";s:16:"globalextra_help";s:189:"A field of text for general-purpose use by template authors, like the extra field of each test case, but global to all tests. Available to the template author as {{ QUESTION.globalextra }}.";s:9:"graphhelp";s:864:"- Double click at a blank space to create a new node/state.
- Click on a link/node then press the Delete key to remove it (or function-delete on a Mac).
- Double click an existing node to "mark" it e.g. as an accept state for Finite State Machines
  (FSMs). Double click again to unmark it.
- Click and drag to move a node.
- Alt click (or Ctrl Alt click) and drag to move a (sub)graph.
- Shift click inside one node and drag to another to create a link.
- Shift click on a blank space, drag to a node to create a start link (FSMs only).
- Click and drag a link to alter its curve.
- Click on a link/node to edit its text.
- Click in link text and drag to move it.
- Typing _ followed by a digit makes that digit a subscript.
- Typing \epsilon creates an epsilon character (and similarly for \alpha, \beta etc).
- Ctrl+z to undo and Ctrl+y or Ctrl+Shift+z to redo.";s:17:"goodemptyprecheck";s:6:"Passed";s:9:"gotcolhdr";s:3:"Got";s:6:"grader";s:6:"Grader";s:7:"grading";s:7:"Grading";s:15:"gradingcontrols";s:16:"Grading controls";s:20:"gradingcontrols_help";s:4201:"The default 'exact match' grader
awards marks only if the output from the run exactly matches the expected value defined
by the testcase. Trailing white space is stripped from all lines, and any trailing
blank lines are deleted, before the
equality test is made.

The near-equality grader is similar except that it
also collapses multiple spaces and tabs to a single space, deletes all blank
lines and converts the strings to lower case.

The 'regular expression' grader uses the 'expected'
field of the test case as a regular expression (without PERL-type delimiters)
and tests the output to see
if a match to the expected result can be found anywhere within the output. For
example, an expected value of 'ab.*z' would match any output that contains the
the characters 'ab' anywhere in the output and a 'z' character somewhere later.
To force matching of the entire output, start and end the regular expression
with '\A' and '\Z' respectively. Regular expression matching uses MULTILINE
and DOTALL options.

The 'template grader' option assumes that the output
from the program is actually a
grading result, i.e. that the template tests *and grades* the student answer.
The only output from such a template program must be a JSON-encoded record.

If the template is a per-test template (i.e., not a combinator), the JSON string must describe a row of the
results table and should contain at least a 'fraction' field, which is multiplied by TEST.mark to decide how
many marks the test case is awarded. It should usually also contain a 'got'
field, which is the value displayed in the 'Got' column of the results table.
The other columns of the results table (testcode, stdin, expected) can also
be defined by the template grading program and will be used instead of the values from
the testcase. As an example, if the output of the program is the string
<code>{"fraction":0.5, "got": "Half the answers were right!"}</code>, half marks would be
given for that particular test case and the 'Got' column would display the
text "Half the answers were right!". Other columns can be added to the result
table by adding extra attributes to the JSON record and also to the question's
Result Columns field.

If the template is a combinator, the JSON string output by the template grader
should again contain a 'fraction' field, this time for the total mark,
and may contain zero or more of 'prologuehtml', 'testresults',
'epiloguehtml', 'columnformats', 'showoutputonly', 'showdifferences'
and 'graderstate'.
The 'prologuehtml' and 'epiloguehtml' fields are html
that is displayed respectively before and after the (optional) result table. The
'testresults' field, if given, is a list of lists used to display some sort
of result table. The first row is the column-header row and all other rows
define the table body. Two special column header values exist: 'iscorrect'
and 'ishidden'. The 'iscorrect' column(s) are used to display crosses or
ticks for 0 and 1 respectively. The 'ishidden' column isn't
actually displayed but 0 or 1 values in the column can be used to turn on and
off row visibility. Students do not see hidden rows but markers and other
staff do. If a 'testresults' table is supplied an optional
'columnformats' field can also be supplied. This should be a list
of strings, one per column excluding the 'iscorrect' and the 'ishidden'
columns. The strings specify the format to be used to display the cell values;
currently the only supported formats are '%s' for a normal string display
(which is sanitised and wrapped in a 'pre' element) and '%h' for an html
value that should not be further processed before display.
The 'showdifferences' field turns on display of a 'Show Differences'
button after the results table if the awarded mark fraction is not 1.0.
The 'showoutputonly' field, if true, is used when the question is to be
used only to display the output and perhaps images from a run, with no mark.
The 'graderstate' variable is a string value that the question author can
use to pass grading information between question attempts. If included
in the grading response to a submission it will be available on the next
submission as the Twig variable 'QUESTION.stepinfo.graderstate'.
";s:29:"graph_ui_invalidserialisation";s:30:"GraphUI: invalid serialisation";s:19:"graphui_isfsm_descr";s:156:"True if the graph represents a Finite State Machine, in which case it can contain an incoming edge from nowhere (the start edge) and can have 'accept' nodes";s:24:"graphui_isdirected_descr";s:26:"True if edges are directed";s:24:"graphui_noderadius_descr";s:30:"The radius of a node in pixels";s:22:"graphui_fontsize_descr";s:54:"The font size in points used for node and edge labels.";s:26:"graphui_helpmenutext_descr";s:103:"Text which if non-empty replaces the standard help menu text defined in the CodeRunner language strings";s:24:"graphui_textoffset_descr";s:87:"The offset in pixels of a link label from its link (deprecated - use dragging instead).";s:31:"graphui_locknodepositions_descr";s:265:"If true, prevents the user from moving nodes. Useful when the answer box is preloaded with a graph that the student has to annotate by changing node or edge labels or by adding/removing edges. Note, though that nodes can still be added and deleted. See locknodeset.";s:25:"graphui_locknodeset_descr";s:102:"If true, prevents the the user from adding or deleting nodes or toggling node types to/from acceptors.";s:28:"graphui_locknodelabels_descr";s:112:"If true, prevent the user from editing node labels. This will also prevent any new nodes having non-empty labels";s:31:"graphui_lockedgepositions_descr";s:405:"If true prevents the user from dragging edges to change their curvature. Possibly useful if the answer box is preloaded with a graph that the student has to annotate by changing node or edge labels or by adding/removing edges. Also ensures that edges added by a student are straight, e.g. to draw a polygon on a set of given points. Note, though that edges can still be added and deleted. See lockedgeset.";s:25:"graphui_lockedgeset_descr";s:56:"If true prevents the user from adding or deleting edges.";s:28:"graphui_lockedgelabels_descr";s:103:"True to prevent the user from editing edge labels. This also prevents any new edges from having labels.";s:6:"hidden";s:6:"Hidden";s:9:"hidecheck";s:10:"Hide check";s:11:"hidedetails";s:12:"Hide details";s:15:"hidedifferences";s:16:"Hide differences";s:4:"HIDE";s:4:"Hide";s:12:"HIDE_IF_FAIL";s:12:"Hide if fail";s:15:"HIDE_IF_SUCCEED";s:15:"Hide if succeed";s:14:"hiderestiffail";s:17:"Hide rest if fail";s:19:"hoisttemplateparams";s:25:"Hoist template parameters";s:12:"howtogetmore";s:100:"For more detailed information, save the question with 'Validate on save' unchecked and test manually";s:21:"htmlui_html_src_descr";s:84:"Sets the source for the HTML code. Must be either 'globalextra' or 'prototypeextra'.";s:31:"htmlui_sync_interval_secs_descr";s:123:"The time interval in seconds between calls to sync the UI contents back to the question answer. 0 for no such auto-syncing.";s:29:"htmlui_enable_in_editor_descr";s:192:"If true, use the UI to display the sample answer and answer preload within the question editing form, rather than the serialised version. Set this to false if using Twig in the HTML src field.";s:14:"htmluiloadfail";s:83:"The HTML UI plugin failed to initialise. Probably the JSON state string is invalid.";s:18:"illegaluiparamname";s:64:"The following are not valid parameters for the {$a->uiname} UI: ";s:20:"iscombinatortemplate";s:13:"Is combinator";s:11:"ideone_user";s:18:"Ideone server user";s:16:"ideone_user_desc";s:104:"The login name to use when connecting to the deprecated Ideone server (if the ideone sandbox is enabled)";s:11:"ideone_pass";s:22:"Ideone server password";s:16:"ideone_pass_desc";s:102:"The password to use when connecting to the deprecated Ideone server (if the ideone sandbox is enabled)";s:16:"info_unavailable";s:68:"Question type information is not available for customised questions.";s:13:"illegalformat";s:46:"Illegal format ({$a->format}) in columnformats";s:11:"inputcolhdr";s:5:"Input";s:23:"insufficientattachments";s:38:"Not enough attachments, {$a} required.";s:12:"is_prototype";s:16:"Use as prototype";s:11:"jobe_apikey";s:12:"Jobe API-key";s:16:"jobe_apikey_desc";s:141:"The API key to be included in all REST requests to the Jobe server (if required). Max 40 chars. Leave blank to omit the API Key from requests";s:9:"jobe_host";s:11:"Jobe server";s:14:"jobe_host_desc";s:550:"The host name of the Jobe server plus the port number if other than port 80, e.g. jobe.somewhere.edu:4010. The URL for the Jobe request is obtained by default by prefixing this string with http:// and appending /jobe/index.php/restapi/<REST_METHOD>. You may either specify the https:// protocol in front of the host name (e.g. https://jobe.somewhere.edu) if the Jobe server is set behind a reverse proxy which act as an SSL termination. Multiple jobe servers, separated by a semicolon, are possible for handling higher loads: one is chosen at random.";s:12:"jobe_host_ws";s:35:"Jobe server to use for web services";s:17:"jobe_host_ws_desc";s:488:"The sandbox server web service will use whatever sandbox is configured for the specified
    language. This is virtually always a Jobe server, and the particular Jobe server to use is configured via the admin interface (above).
    However, for best web service security it is better to use an alternative
    Jobe server, set by this field. Multiple jobe servers, separated by a semicolon, are possible for handling higher loads: one is chosen at random. Leave blank to use the default. ";s:17:"jobe_warning_html";s:319:"<p style='background-color:yellow'>Run using the University of Canterbury's Jobe server. This is for initial testing only. Please set up your own Jobe server as soon as possible. See <a href='https://github.com/trampgeek/moodle-qtype_coderunner/blob/master/Readme.md#sandbox-configuration' target='_blank'>here</a>.</p>";s:20:"jobe_canterbury_html";s:114:"<p style='color:gray; font-style:italic; font-size:smaller'>Run on the University of Canterbury's Jobe server.</p>";s:8:"language";s:16:"Sandbox language";s:9:"languages";s:9:"Languages";s:14:"languages_help";s:1798:"The sandbox language is the computer language used
to run the submission. This should not usually need altering from the value in the
parent template; tweak it at your peril.

Ace-language is the
language used by the Ace code editor (if enabled) for the student's answer.
By default this is the same as the sandbox language; enter a different
value here only if the template language is different from the language
that the student is expected to write (e.g. if a Python template is
used to preprocess a student's C program and then execute it in a subprocess).

Multi-language questions, that is questions that students can answer in
more than one language, are enabled by setting the Ace-language to a comma-separated
list of languages. Students are then presented with a drop-down menu to select
the language in which their answer is written. If exactly one of the languages
has an asterisk ('\*') appended, that language is chosen as the default language,
which is selected as the initial state of the drop-down menu. For example,
an Ace-language value of "C,C++,Java\*,Python3" would allow student to submit in
C, C++, Java or Python3 but the drop-down menu would initially show Java which
would be the default. If no default is specified the
initial state of the drop-down is empty and the student must choose a language.
Multilanguage questions require a special template that uses the {{ANSWER\_LANGUAGE}}
template variable to control how to execute the student code. See the built-in
sample multilanguage question type. The {{ANSWER\_LANGUAGE}} variable is defined
<i>only</i> for multilanguage questions.

If the author wishes to supply a sample answer to a multilanguage question,
they must write it in the default language, if specified, or the
first of the allowed languages otherwise.";s:19:"languageselectlabel";s:8:"Language";s:14:"legacyuiparams";s:139:"UI parameters can no longer be defined within the template parameters field. Please move the following to the UI parameters field instead: ";s:15:"legacyuiparams2";s:176:"UI parameters can no longer be defined within the template parameters field. Please move the following to the UI parameters field instead, removing the '{$a->uiname}_' prefix: ";s:23:"listprototypeduplicates";s:89:"Question ID: {$a->id} <ul><li>Name: {$a->name}</li><li>Category: {$a->category}</li></ul>";s:18:"loadprototypeerror";s:171:"Reverted to question type: '{$a->oldtype}' <br>Could not load question type '{$a->crtype}' as the prototype is non-unique in the following questions:</p>{$a->outputstring}";s:4:"mark";s:4:"Mark";s:7:"marking";s:15:"Mark allocation";s:12:"markinggroup";s:7:"Marking";s:17:"markinggroup_help";s:1309:"If 'All-or-nothing' is checked, all test cases must be satisfied
for the submission to earn any marks. Otherwise, the mark is obtained
by summing the marks for all the test cases that pass
and expressing this as a fraction of the maximum possible mark.
The per-test-case marks can be specified only if the all-or-nothing
checkbox is unchecked. If using a template grader that awards
part marks to test cases, 'All-or-nothing' should generally be unchecked.

The mandatory penalty regime is a comma-separated list of penalties (each a percent)
to apply to successive submissions. These are absolute, not cumulative. As a
special case the last penalty can be '...' to mean "extend the previous
two penalties as an arithmetic progression up to 100". For example,
<code>0,5,10,30,...</code> is equivalent to <code>0,5,10,30,50,70,90,100</code>.
If there are more submissions than defined penalties, the last value is used.
Spaces can be used in lieu of commas as a separator.

The default penalty regime can be set site-wide by a system administrator using
Site administration > Plugins > Question types > CodeRunner.

Set the penalty regime to '0' for zero penalties on all submissions.

The penalty regime is ignored and no penalties are applied if the quiz is
run using the 'Adaptive (no penalties)' behaviour.";s:11:"maxfilesize";s:29:"Max allowed file size (bytes)";s:16:"maxfilesize_help";s:166:"Select the maximum file upload size (bytes). Allowing large file uploads with large classes can impact performance and and disk space on both Moodle and Jobe servers.";s:11:"memorylimit";s:13:"MemLimit (MB)";s:14:"missinganswers";s:15:"missing answers";s:20:"missingorbadfraction";s:80:"Bad or missing fraction in output from template grader. Output was: {$a->output}";s:13:"missingoutput";s:56:"You must supply the expected output from this test case.";s:16:"missingprototype";s:232:"This question was defined to be of type '{$a->crtype}' but the prototype does not exist, or is unavailable in this context. You should Cancel and try to (re)install the prototype.
Proceed to edit only if you know what you are doing!";s:17:"missingprototypes";s:18:"Missing prototypes";s:27:"missingprototypewhenrunning";s:79:"Broken question (missing or duplicate prototype '{$a->crtype}'). Cannot be run.";s:15:"missinguiparams";s:58:"The following UI parameters are required but not defined: ";s:16:"multipledefaults";s:47:"At most one language can be selected as default";s:18:"multipleprototypes";s:44:"Multiple prototypes found for '{$a->crtype}'";s:16:"mustrequirefewer";s:51:"You cannot require more attachments than you allow.";s:18:"nearequalitygrader";s:18:"Nearly exact match";s:18:"nodetailsavailable";s:44:"Select a question type to see detailed help.";s:14:"nouiparameters";s:45:"The {$a->uiname} UI does not take parameters.";s:7:"noqtype";s:25:"No question type selected";s:10:"nolanguage";s:28:"Please select language first";s:10:"morehidden";s:35:"Some hidden test cases failed, too.";s:15:"noerrorsallowed";s:59:"Your code must pass all tests to earn any marks. Try again.";s:14:"nonnumericmark";s:16:"Non-numeric mark";s:14:"nosampleanswer";s:16:"No sample answer";s:8:"nooutput";s:14:"< No output! >";s:18:"negativeorzeromark";s:30:"Mark must be greater than zero";s:7:"options";s:7:"Options";s:8:"ordering";s:8:"Ordering";s:22:"bulktestoverallresults";s:15:"Overall results";s:14:"overloadoninit";s:57:"Sandbox server overload prevented question initialisation";s:30:"outputdisplayarea_invalid_mode";s:28:"Invalid output display mode:";s:30:"outputdisplayarea_invalid_json";s:40:"Error parsing JSON. Output from wrapper:";s:37:"outputdisplayarea_missing_json_fields";s:47:"Output display JSON is missing required fields:";s:41:"outputdisplayarea_missing_image_extension";s:57:"Cannot display image, include file extension in filename:";s:6:"passes";s:6:"passes";s:13:"penaltyregime";s:24:"(penalty regime: {$a} %)";s:18:"penaltyregimelabel";s:15:"Penalty regime:";s:4:"pass";s:4:"Pass";s:10:"pluginname";s:10:"CodeRunner";s:16:"pluginnameadding";s:28:"Adding a CodeRunner question";s:17:"pluginnameediting";s:29:"Editing a CodeRunner question";s:17:"pluginnamesummary";s:52:"CodeRunner: runs student-submitted code in a sandbox";s:15:"pluginname_help";s:257:"Use the 'Question type' combo box to select the
computer language and question type that will be used to run the student's submission.
Specify the problem that the student must write code for, then define
a set of tests to be run on the student's submission";s:15:"pluginname_link";s:24:"question/type/coderunner";s:8:"precheck";s:8:"Precheck";s:17:"precheck_disabled";s:8:"Disabled";s:14:"precheck_empty";s:5:"Empty";s:17:"precheck_examples";s:8:"Examples";s:17:"precheck_selected";s:8:"Selected";s:12:"precheck_all";s:3:"All";s:13:"precheck_help";s:1355:"Set what button are available for students to
submit answers. Usually at least a Check button is shown but this can be
hidden (e.g. for use in Deferred Feedback contexts) if <i>Hide check</i> is checked.

If Precheck is enabled, students will have an extra button to the left of the
usual check button to give them a penalty-free run to check their code against
a subset of the question test cases. Then<ul>
<li>If 'Empty' is selected, a single run
will be done with the per-test template using a testcase in which all the
fields (testcode, stdin, expected, etc) are the empty string. Non-empty output
is deemed to be a precheck failure. Use with caution:
some question types will not handle this correctly, e.g. write-a-program questions
that generate output.
</li><li>If 'Examples' is selected, the code will
be tested against all the tests for which 'use_as_example' has been checked.
</li><li>If 'Selected' is selected, an extra UI element is added to each test case
to allow the author to select a specific subset of the tests.
</li><li>If 'All' is selected, all test cases are run (although their behaviour might
be different from the normal Check, if the template code so chooses).
</ul>
The template can check whether or not the run is a precheck run using the
Twig parameter {{ IS_PRECHECK }}, which is "1" during precheck runs and
"0" otherwise.";s:13:"precheck_only";s:13:"Precheck only";s:19:"precheckingemptyset";s:43:"Prechecking examples, but there aren't any!";s:16:"privacy:metadata";s:69:"The CodeRunner question type plugin does not store any personal data.";s:19:"proceed_at_own_risk";s:65:"Editing a built-in question prototype?! Proceed at your own risk!";s:17:"prototypecontrols";s:11:"Prototyping";s:15:"prototypeexists";s:49:"This is a prototype; cannot change question type.";s:14:"prototypeextra";s:15:"Prototype extra";s:19:"prototypeextra_help";s:184:"A field of text for general-purpose use by question type authors, like global extra, but part of the prototype state. Available to the template author as {{ QUESTION.prototypeextra }}.";s:14:"prototypeusage";s:51:"CodeRunner question prototype usage for course {$a}";s:19:"prototypeusageindex";s:17:"Available courses";s:22:"prototypecontrols_help";s:1062:"If 'Is prototype' is true, this question becomes a prototype for other questions.
After saving, the specified question type name will appear in the dropdown list
of question types. New questions based on this type will then by default inherit
all the customisation attributes specified for this question. Subsequent changes
to this question will then affect all derived questions unless they are
themselves customised, which breaks the connection.

Prototypal inheritance is
single-level only, so this question, when saved as a prototype, loses its
connection to its original base type, becoming a new base type in its own right.
Be warned that when exporting derived questions you must ensure that this
question is included in the export, too, or the derived question will be an
orphan when imported into another system. Also, you are responsible for keeping
track of which questions you are using as prototypes; it is strongly recommended
that you rename the question to something like 'PROTOTYPE_for_my_new_question_type'
to make subsequentmaintenance easier.";s:15:"prototype_error";s:48:"*** PROTOTYPE LOAD FAILURE. DON'T SAVE THIS! ***";s:22:"prototype_load_failure";s:25:"Error loading prototype: ";s:23:"prototype_missing_alert";s:66:"Missing prototype: Check if {$a} prototype exists in this context.";s:25:"prototype_duplicate_alert";s:72:"Duplicate prototype: Duplicate {$a} prototypes exist. Can only load one.";s:10:"prototypeQ";s:13:"Is prototype?";s:16:"qtype_c_function";s:1242:"<p>A question type for C write-a-function questions.
The student answer is expected to be a complete C function, but it can optionally
be preceded by other self-contained C code such as preprocessor directives and
support functions.</p>
<p>The test code for such questions typically calls the student function with
some test arguments and prints the result, such as
<pre>printf("%d\n", someIntFunction(blah1, blah2))</pre>
The test case's <i>Expected</i> field is the expected output from the test.</p>
<p>
If there is no standard input supplied for any of the test cases, a single
test program is constructed, consisting of:</p>
<ol>
<li>The following standard #includes: stdlib.h, ctype.h, string.h, stdbool.h, math.h</li>
<li>The student answer.</li>
<li>A sequence of blocks wrapped in braces for each of the given test cases.
Each block contains just the test case's test code. There is also a <i>printf</i>
statement added between code blocks to print a special separator that is used
to split the output back into individual test case outputs.</li>
</ol>
<p>However, if any of the test cases has non-empty standard input, multiple test
programs are run, one for each test case.
</p><p>The test case's <i>extra</i> field is ignored.</p>";s:18:"qtype_cpp_function";s:1301:"<p>A question type for C++ write-a-function questions.
The student answer is expected to be a complete C++ function, but it can optionally
be preceded by other self-contained C++ code such as preprocessor directives and
support functions.</p>
<p>In each test case, the test code for such questions typically calls the student function with
some test arguments and prints the result, such as
<pre>cout << someIntFunction(blah1, blah2))</pre>
The test case's <i>Expected</i> field is the expected output from the test.
<p>
If there is no standard input supplied for any of the test cases, a single
test program is constructed, consisting of:</p>
<ol>
<li>The following standard #includes: iostream, fstream, string, math, vector and algorithm</li>
<li><code>using namespace std;</code></li>
<li>The student answer</li>
<li>A sequence of blocks wrapped in braces for each of the given test cases.
Each block consists of the test case's <i>extra</i> field (usually empty)
followed by the test code. There is also a <i>printf</i>
statement added between code blocks to print a special separator that is used
to split the output back into individual test case outputs.</li>
</ol>
<p>However, if any of the test cases has non-empty standard input, multiple test
programs are run, one for each test case.
</p>";s:15:"qtype_c_program";s:698:"<p>Used for C write-a-program questions, where
there is no per-test-case code, and the different tests just use different
standard input (stdin) data. The student answer is expected to be a complete
runnable program, which is run as-is, without modification by CodeRunner,
once for each test case. The values of the test code and extra fields of each
test case are ignored.</p><p>If you need to set special compile or link
arguments for the question, you can customise it (click the Customise
checkbox), open the <i>Advanced customisation</i> section, and enter suitable
values into the <i>Sandbox &gt; Parameters</i> field. For example<pre>
{"linkargs":["-lm"]}</pre>to link with the math library.";s:17:"qtype_cpp_program";s:379:"<p>Used for C++ write-a-program questions, where
there is no per-test-case code, and the different tests just use different
standard input (stdin) data. The student answer is expected to be a complete
runnable program, which is run as-is, without modification by CodeRunner,
once for each test case. The values of the test code and extra fields of each
test case are ignored.</p>";s:20:"qtype_directed_graph";s:3184:"<p>A python3 question type that asks the student to draw
a directed graph to satisfy some specification.
<h4>Template parameter</h4>
<p><b>extra</b>: can be set to <i>pretest</i> or <i>posttest</i> to have the <i>extra</i> code
run before/after the test code, respectively. Default: <i>posttest</i> - for backward
compatibility (originally the extra code always ran after the test code).</p>
<h4>Usage information</h4>
The question author has to write
Python3 code to check the resulting graph.</p><p>Note that it is not actually
necessary to use this question type for directed graphs, as the functionality
is mainly provided by the GraphUI plugin. If the graph pre-processing performed
by this question type does not suit your needs, you can instead just use a normal
Python3 question (or any other language), set the UI to GraphUI, and analyse
the JSON-serialised version of the graph (the Twig STUDENT_ANSWER&nbsp; variable)
yourself. However, this question type does provide an example of how to use the
GraphUI plugin. Click <i>Customise</i>&nbsp;to see the template code.</p>
<p>The specification will ask the student to draw a directed graph to satisfy
certain requirements. It might for example be a DFA (deterministic finite-state
automaton) or a Turning machine. The test case code and/or the extra code will
then analyse the graph and print a message to the student, such as OK if the
graph is correct or a suitably informative error message otherwise.</p>
<p>The template for this question analyses the JSON-serialised graph, extracting
its topology in the form of an adjacency dictionary&nbsp;<i>graph</i>. This
variable is available to the test or extra code in the test case. Keys in the
dictionary are node names, if given, or arbitrary node identifying labels of
the form #1, #2 etc otherwise. Values in the dictionary are lists of outgoing
edges, sorted by neighbour node name or identifier, each edge being a tuple
(neighbourId, edgeLabel).</p><p>Each entry in the adjacency list is of the form
(nodeNameOrId, neighbours) where neighbours is a list of tuples
(neighbourNodeNameOrId, edgeLabel). If nodes are given names, those are used
as node identifiers, otherwise the names #1, #2 etc are used. The adjacency
list and the neighbour list are both sorted in order of node name or identifier.</p>
<p>The template is a combinator one: the <i>testcode</i>&nbsp;and
<i>extra</i>&nbsp;code are both executed for each test cae. With the <i>extra</i>
code running after (posttest) the test case, by default.</p><p>As a simple
example, if the specification were just "Draw a directed graph with two nodes
labelled A and B, with an edge from A to B", a suitable test case (albeit with
unhelpful error output) might be:</p><pre>
if set(graph.keys()) == {'A', 'B'} and len(graph['A']) == 1 and len(graph['B']) == 0 and graph['A'][0][0] == 'B':
    print('OK')
else:
    print('Nope')
</pre>
<p>Alternatively, there could be a set of test cases, each one checking
one of the aspects of the specification. For example, the first test case might
print the sorted keys, expecting to see 'A', 'B'. The second test case might
print the outgoing edges from node 'A', and so on.</p>";s:16:"qtype_java_class";s:1337:"<p>A Java write-a-class question, where the student submits a
complete class as their answer. Each test will  typically instantiate an object of the specified
class and perform one or more tests on it. It is not a combinator question type, meaning that
each test case runs as a separate sandbox program.
</p><p>The program generated for each test case consists of the student answer, with
the <i>public</i>&nbsp;attribute stripped if present. That (now local)
class definition is followed by a public <i>__Tester__&nbsp;</i>&nbsp;class that
has a <i>main</i>&nbsp;method that instantiates the Tester class and calls its
<i>runTests</i>&nbsp;method. The <i>runTests</i>&nbsp;method simply contains the
test case code. See the template for clarification.</p><p>It should be noted that
the algorithm used to strip the public attribute from the student-supplied class
is simplistic; it only works if the words <i>public class</i>&nbsp;exist exactly
once in the student code, separated by a single space.</p>
<p>The test case extra field is ignored.</p>
<p>This question type is inefficient if there are many test, as a separate
compile-and-execute job is sent to the sandbox for each test case. This could be
resolved by writing a combinator-style question type. See the coderunner
documentation (coderunner.org.nz) for more information.</p>";s:17:"qtype_java_method";s:603:"<p>Used for Java write-a-method questions where the
student is asked to write a method that is essentially a standalone function.
The author-supplied test is typically just one or two lines of code that
(apparently) just call the student supplied method, as in C. Under the hood, the
template constructs a Main class containing the student-supplied method
(and any other support methods, if they choose to write them) plus a 'runTests'
method that wraps the testcase(s). The main function for the class constructs an
instance of Main and calls its runTests method. See the template code for details.</p>";s:18:"qtype_java_program";s:715:"<p>A Java write-a-program question where the student
submits a complete program as their answer. The program is compiled and executed for each
test case. There is no test code, just stdin test data, though this isn't
actually checked: caveat emptor. The extra fields of the test cases are likewise
ignored.</p>
<p>This question type becomes very inefficient if there are many test cases, since
each one necessitates a full compile-and-execute cycle on the Jobe server. It is
possible to wrap all tests into a single Python job that is sent to the sandbox
server and compiles the program just once, then runs it on each test case.
For details of this approach, see the question author forum on
coderunner.org.nz.</p>";s:19:"qtype_multilanguage";s:1682:"<p>A "write a program" style
of question in which the student can submit an answer in any one of several
different languages. The languages C, C++, Java, Python3, PHP and JavaScript (nodejs)
are standard on Jobe servers so should all work directly. The question type also
allows for the use of perl, ruby, golang and C# but these require the
appropriate additional compilers and/or interpreters to be installed on Jobe.
For example, <code>sudo apt-get install mono-mcs</code> to install the mono C#
compiler, mcs.</p>
<p>If the question author supplies a sample answer, they can specify the language
of their answer in one of three ways. <ol><li>By adding a template parameter like
<code>{"answer_language": "cpp"}</code> to specify the language they are using.</li>
<li>By using the default language, if one is set. The default languages is denoted
by an asterisk after the language name in the "Ace language" field in the
Advanced Customisation panel, if the author is using a customised question. There
is no default language otherwise.</li>
<li>By using the first language listed in the "Ace language" field in the
Advanced Customisation panel - default is C.</li></ol></p>
<p>The student's question answer
box has a drop-down menu at the top, with which the student must select
the language in which their answer is written.</p>
<p>Further languages can be added, if supported on the Jobe server, by
adding the language name to the <i>AceLang</i> field of the question edit
form and then extending the template (q.v.) to handle the new language.</p>
<p>The submitted program code is run as-is for each test case. The testcode
and extra fields of each test case are ignored.</p>";s:12:"qtype_nodejs";s:536:"<p>A JavaScript question type, run using nodejs. The
test program to be executed starts with the student answer. That is followed
by each of the test case codes in turn, with a separator string being printed
between them. However, if there is any standard input present for any of the
test cases, a separate test run will be done for each test case.</p><p>
If there is a risk of side-effects from a test case affecting later test cases
you can add standard input to any one of the test cases to force the one-run-per-test-case
mode.</p>";s:21:"qtype_octave_function";s:598:"<p>A question type that specifies an
Octave function, which the student has to submit in its entirety. Each test
case will typically call the student function with test arguments and print
the result or some value derived from it. If there is no standard input present
in any of the questions, the program consists of the student answer, the
statement <code>format free</code> and the test code from each test case,
plus an extra <i>disp</i> statement to print a separator string between
test case outputs.</p><p>If there is any standard input present, each test
case is instead run separately.</p>";s:21:"qtype_pascal_function";s:331:"<p>A Pascal question type where the student
 is asked to write a procedure or function. The program to be run consists of
 the student answer followed by the CodeRunner <i>testcode</i> wrapped
 in <code>begin ... end.</code>.<br>
 This is not a combinator question type, so a separate jobe run will be done
 for each test case.</p>";s:20:"qtype_pascal_program";s:253:"<p>A Pascal question type where the student
 answer is a complete Pascal program. The program is compiled and run once for
 each test case, using the standard input provided in the test case and
 ignoring the <i>testcode</i> and <i>extra</i> fields.</p>";s:9:"qtype_php";s:801:"<p>A php question in which the student submission is
php code. In the simplest case, the student code will start with</p><pre>
&lt;?php
</pre>but <i>will not close the PHP tag</i>. The reason for the non-closure
can be seen by inspecting the template: the student answer is followed by each
of the test case test codes. If instead you wish the student code to end by
closing the PHP tag, you should edit the template to re-open the PHP tag before
the sequence of tests.
</p><p>The output from each test case, which should match the test case
<i>expected</i> field, will be the output from the student's PHP code
(including any content outside the scope of &lt;?php...?&gt; tags) plus the
output from the test code.</p><p>Inspect the template code (by clicking
<i>Customise</i>) to understand this.</p>";s:13:"qtype_python2";s:1083:"<p>A Python2 question type, which can handle
write-a-function, write-a-class or write-a-program question types. For each
test case, the student-answer code is executed followed by the test code.
Thus, for example, if the student is asked to write a function definition,
their definition will be executed first, followed by the author-supplied
test code, which will typically call the function and print the result or
some value derived from it.</p>
<p>If there are no standard inputs defined for all test cases, the question
actually wraps all the tests
into a single run, printing a separator string between each test case output.
Please be aware that this isn't necessarily the same as running each test
case separately. For example, if there are any global variables defined by
the student code, these will hold their values across the multiple runs.
If this is likely to prove a problem, the easiest work-around is to define
one of the test case standard input fields to be a non-empty value - this
forces CodeRunner into a fallback mode of running each test case separately.</p>";s:13:"qtype_python3";s:1083:"<p>A Python3 question type, which can handle
write-a-function, write-a-class or write-a-program question types. For each
test case, the student-answer code is executed followed by the test code.
Thus, for example, if the student is asked to write a function definition,
their definition will be executed first, followed by the author-supplied
test code, which will typically call the function and print the result or
some value derived from it.</p>
<p>If there are no standard inputs defined for all test cases, the question
actually wraps all the tests
into a single run, printing a separator string between each test case output.
Please be aware that this isn't necessarily the same as running each test
case separately. For example, if there are any global variables defined by
the student code, these will hold their values across the multiple runs.
If this is likely to prove a problem, the easiest work-around is to define
one of the test case standard input fields to be a non-empty value - this
forces CodeRunner into a fallback mode of running each test case separately.</p>";s:22:"qtype_undirected_graph";s:3187:"<p>A python3 question type that asks the student to draw
an undirected graph to satisfy some specification. </p>
<h4>Template parameter</h4>
<p><b>extra</b>: can be set to <i>pretest</i> or <i>posttest</i> to have the <i>extra</i> code
run before/after the test code, respectively. Default: <i>posttest</i> - for backward
compatibility (originally the extra code always ran after the test code).</p>
<h4>Usage information</h4>
<p>The question author has to write
Python3 code to check the resulting graph.</p><p>Note that it is not actually
necessary to use this question type for undirected graphs, as the functionality
is mainly provided by the GraphUI plugin. If the graph pre-processing performed
by this question type does not suit your needs, you can instead just use a normal
Python3 question (or any other language), set the UI to GraphUI, and analyse
the JSON-serialised version of the graph (the Twig STUDENT_ANSWER&nbsp; variable)
yourself. However, this question type does provide an example of how to use the
GraphUI plugin. Click <i>Customise</i>&nbsp;to see the template code.</p>
<p>The specification will ask the student to draw an undirected graph to satisfy
certain requirements, e.g. a graph representation of a set of towns connected
by two-way roads. The test case code and/or the extra code will
then analyse the graph and print a message to the student, such as OK if the
graph is correct or a suitably informative error message otherwise.</p>
<p>The template for this question analyses the JSON-serialised graph, extracting
its topology in the form of an adjacency dictionary&nbsp;<i>graph</i>. This
variable is available to the test or extra code in the test case. Keys in the
dictionary are node names, if given, or arbitrary node identifying labels of
the form #1, #2 etc otherwise. Values in the dictionary are lists of edges,
sorted by neighbour node name or identifier, each edge being a tuple
(neighbourId, edgeLabel).</p><p>Each entry in the adjacency list is of the form
(nodeNameOrId, neighbours) where neighbours is a list of tuples
(neighbourNodeNameOrId, edgeLabel). If nodes are given names, those are used
as node identifiers, otherwise the names #1, #2 etc are used. The adjacency
list and the neighbour list are both sorted in order of node name or identifier.</p>
<p>The template is a combinator one: the <i>testcode</i>&nbsp;and
<i>extra</i>&nbsp;code are both executed for each test cae. With the <i>extra</i>
code running after (posttest) the test case, by default.</p>
<p>As a simple
example, if the specification were just "Draw an undirected graph with two nodes
labelled A and B, with an edge between the two nodes", a suitable test case (albeit with
unhelpful error output) might be:</p><pre>
if set(graph.keys()) == {'A', 'B'} and len(graph['A']) == 1 and len(graph['B']) == 1 and graph['A'][0][0] == 'B':
    print('OK')
else:
    print('Nope')
</pre>
<p>Alternatively, there could be a set of test cases, each one checking
one of the aspects of the specification. For example, the first test case might
print the sorted keys, expecting to see 'A', 'B'. The second test case might
print the edges connected to node 'A', and so on.</p>";s:21:"qtype_python3_w_input";s:1905:"<p>A Python3 question type, which can handle
write-a-function, write-a-class or write-a-program question types. It differs
from the slightly simpler <i>python3</i> question type in that the usual
python3 <i>input</i> function is replaced with a custom version that echoes
standard input to standard output as it is consumed. This results in the output
mimicking that which is seen by students when testing with keyboard input.
It is recommended instead for the <i>python3</i> question type for any
questions that involve calls to <i>input</i> in introductory programming
courses, where students are likely to be confused by the non-echoing of
standard input when taken from a file.</p><p>A slight downside of this question
type compared to the <i>python3</i> question type is that any error messages
in the student code will have confusing line numbers, since the substitute
input function is inserted before the student code.</p>
<p>For each
test case, the student-answer code is executed followed by the test code.
Thus, for example, if the student is asked to write a function definition,
their definition will be executed first, followed by the author-supplied
test code, which will typically call the function and print the result or
some value derived from it.</p>
<p>If there are no standard inputs defined for all test cases, the question
actually wraps all the tests
into a single run, printing a separator string between each test case output.
Please be aware that this isn't necessarily the same as running each test
case separately. For example, if there are any global variables defined by
the student code, these will hold their values across the multiple runs.
If this is likely to prove a problem, the easiest work-around is to define
one of the test case standard input fields to be a non-empty value - this
forces CodeRunner into a fallback mode of running each test case separately.</p>";s:9:"qtype_sql";s:1108:"<p>A SQL question type, using sqlite3,
 run from Python3. sqlite3 must be installed on the Jobe server for this question
 type.</p>
 <p>The working directory is searched for files with an extension '.db'. If
 there is only one such file, it is used as the sqlite3 database for all tests.
 Multiple .db files currently issues an error message; a possible extension is
 to use different db files for each test, e.g. in sorted order.</p>
 <p>For each test, an sqlite3 command script of the form</p>
 <pre>.mode column<br>.headers on<br>&lt;code in extra&gt;<br>&lt;student answer&gt;<br>&lt;testcode&gt;</pre>
 <p>is run.</p>
 <p>A fresh copy of the db file is used for each test case.&nbsp;</p>
 <p>A template parameter <i>columnwidths</i>&nbsp;can be used to set the report
 column widths. By default sqlite3 sets each column width to be the maximum of
 three numbers: 10, the width of the header, and the width of the first row of data.
 A template string like</p><pre><code>{"columnwidths": [10, 50, 10, 5]}
</code></pre>
<p>will instead use column widths of 10, 50, 10 and 5 for the first four columns.</p>";s:9:"qtypehelp";s:16:"Help with q-type";s:18:"questioncheckboxes";s:13:"Customisation";s:23:"questioncheckboxes_help";s:350:"To customise the question type, e.g. to edit
the question template, user interface or sandbox parameters, click the 'Customise'
checkbox and read the help available on the newly-visible form elements for
more information.

If the template-debugging checkbox is clicked, the program generated
for each Jobe sandbox run will be displayed in the output.";s:17:"questionloaderror";s:23:"Failed to load question";s:15:"questionpreview";s:16:"Question preview";s:12:"questiontype";s:13:"Question type";s:21:"question_type_changed";s:103:"Changing question type. Click OK to reload customisation fields, Cancel to retain your customised ones.";s:17:"questiontype_help";s:543:"Select the particular type of question.

The combo-box selects one of the built-in types, each of which
specifies a particular language and, sometimes, a sandbox in which
the program will be executed. Each question type has a
template that defines how the executable program is built from the
testcase data and the student answer.

The template can be viewed and optionally customised by clicking
the 'Customise' checkbox.

If the template-debugging checkbox is clicked, the program generated
for each testcase will be displayed in the output.";s:19:"questiontypedetails";s:21:"Question type details";s:21:"questiontype_required";s:36:"You must select the type of question";s:15:"qWrongBehaviour";s:194:"Please use Adaptive Behaviour for all CodeRunner questions, or there can be massive performance hits. For example, all questions on a page will need to be regraded when the page is re-displayed.";s:11:"regexgrader";s:18:"Regular expression";s:19:"replacedollarscount";s:49:"This category contains {$a} CodeRunner questions.";s:22:"replaceexpectedwithgot";s:96:"Click on the &lt;&lt; button to replace the expected output of this testcase with actual output.";s:13:"resultcolumns";s:14:"Result columns";s:5:"reset";s:12:"Reset answer";s:10:"resethover";s:60:"Discard changes and reset answer to original preloaded value";s:18:"resultcolumnheader";s:6:"Result";s:18:"resultcolumns_help";s:1996:"By default the result table displays the testcode, stdin, expected and got
columns, provided the columns are not empty. You can change the default, and/or
the column headers by entering a value for the resultcolumns (leave blank for
the default behaviour).

If supplied, the resultcolumns field must be a
JSON-encoded list of column specifiers. Each column specifier is itself a list,
typically with just two or three elements. The first element is the column
header, the second element is the field from the TestResult object being
displayed in the column and the optional third element is an sprintf format
string used to display the field.

The fields available in the standard
TestResult object are: testcode, stdin, expected, got, extra, awarded, and mark.
testcode, stdin, expected and extra are the fields from the testcase while got
is the actual output generated and awarded and mark are the actual awarded mark
and the maximum mark for the testcase respsectively.

Per-test template-graders may
add their own fields, which can also be selected for display. It is also
possible to combine multiple fields into a column by adding extra fields to the
specifier: these must precede the sprintf format specifier, which then becomes
mandatory. For example, to display a Mark Fraction column in the form 0.74/1.00,
say, a column format specifier of ["Mark Fraction", "awarded", "mark",
"%.2f/%.2f"] could be used.

As a further special case, a format of %h means that
the test result field should be taken as ready-to-output HTML and should not be
subject to further processing; this is useful only with custom-grader templates
that generate HTML output, such as SVG graphics.

The default value of
resultcolumns is [["Test", "testcode"],["Input", "stdin"], ["Expected",
"expected"], ["Got", "got"]].

The setting of the resultcolumns field has no effect if a combinator template
grader is being used. The question author is then responsible for formatting
the result table in any desired way.";s:20:"resultcolumnsnotjson";s:47:"Result columns field is not a valid JSON string";s:20:"resultcolumnsnotlist";s:66:"Result columns field must a JSON-encoded list of column specifiers";s:19:"resultcolumnspecbad";s:78:"Invalid column specifier found: each one must be a list of two or more strings";s:18:"resultstring-norun";s:6:"No run";s:29:"resultstring-compilationerror";s:17:"Compilation error";s:25:"resultstring-runtimeerror";s:9:"Run error";s:22:"resultstring-timelimit";s:19:"Time limit exceeded";s:20:"resultstring-success";s:2:"OK";s:24:"resultstring-memorylimit";s:21:"Memory limit exceeded";s:27:"resultstring-illegalsyscall";s:21:"Illegal function call";s:26:"resultstring-internalerror";s:42:"CodeRunner error (IE): please tell a tutor";s:27:"resultstring-sandboxpending";s:42:"CodeRunner error (PD): please tell a tutor";s:26:"resultstring-sandboxpolicy";s:42:"CodeRunner error (BP): please tell a tutor";s:28:"resultstring-sandboxoverload";s:48:"Sandbox server overload. Perhaps try again soon?";s:24:"resultstring-outputlimit";s:16:"Excessive output";s:32:"resultstring-abnormaltermination";s:20:"Abnormal termination";s:10:"run_failed";s:19:"Failed to run tests";s:23:"sampleanswerattachments";s:25:"Sample answer attachments";s:28:"sampleanswerattachments_help";s:62:"If the sample answer needs attachments files, upload them here";s:15:"sandboxcontrols";s:7:"Sandbox";s:20:"sandboxcontrols_help";s:1603:"All jobs are run on the Jobe sandbox, which imposes
constraints on memory, CPU time, file output etc. Here is where you adjust those constraints.

'TimeLimit (secs)' sets the maximum CPU time in seconds  allowed for each sandbox run
and 'MemLimit (MB)' sets the maximum memory the run can use. A blank entry uses the sandbox's
default value (typically 5 secs for the CPU time limit and a language-dependent
amount of memory), but the defaults may not be suitable for resource-demanding
programs. A value of zero for the maximum memory results in no limit being
imposed. The amount of memory specified here is the total amount needed for
the run including all libraries, interpreters, VMs etc.

The 'Parameters' entry
is used to pass further sandbox-specific data, such as compile options and
API-keys. It should generally be left blank but if non-blank it must be a valid
JSON record. In the case of the jobe sandbox, available attributes include
disklimit, streamsize, numprocs, compileargs, linkargs and interpreterargs. For
example <code>{"compileargs":["-std=c89"]}</code> for a C question would force C89
compliance and no other C options would be used. See the jobe documentation
for details. Some sandboxes (e.g. the deprecated Ideone sandbox) may silently ignore any or all of
these settings.

It is possible to select a different jobeserver by defining a 'jobeserver'
parameter and also, optionally, a 'jobeapikey' parameter. For example, if the
'Parameters' field is set to <code>{"jobeserver": "myspecialjobe.com"}</code>, the run
will instead by submitted to the server "myspecialjobe.com".
";s:17:"enable_sandbox_ws";s:26:"Enable sandbox web service";s:22:"enable_sandbox_ws_desc";s:83:"Enable the web service allowing direct
access to the sandbox server (usually Jobe).";s:12:"sandboxerror";s:53:"Error from the sandbox [{$a->sandbox}]: {$a->message}";s:13:"sandboxparams";s:10:"Parameters";s:32:"seethisquestioninthequestionbank";s:38:"See this question in the question bank";s:4:"SHOW";s:4:"Show";s:11:"showcolumns";s:13:"Show columns:";s:16:"showcolumns_help";s:159:"Select which columns of the results table should
be displayed to students. Empty columns will be hidden regardless.
The defaults are appropriate for most uses.";s:11:"showdetails";s:12:"Show details";s:15:"showdifferences";s:16:"Show differences";s:10:"showsource";s:18:"Template debugging";s:17:"sourcecodeallruns";s:37:"Debug: source code from all test runs";s:5:"stdin";s:14:"Standard Input";s:10:"stdin_help";s:70:"The standard input to the test, seen by the template as {{TEST.stdin}}";s:14:"student_answer";s:14:"Student answer";s:13:"submitbuttons";s:14:"Submit buttons";s:14:"supportscripts";s:15:"Support scripts";s:13:"syntax_errors";s:15:"Syntax Error(s)";s:28:"scratchpadui_def_button_name";s:3:"Run";s:32:"scratchpadui_def_scratchpad_name";s:10:"Scratchpad";s:28:"scratchpadui_def_prefix_name";s:18:"Prefix with Answer";s:26:"scratchpadui_def_help_text";s:355:"<p>You can enter code into this panel and click 'Run' to execute it.</p>
<p>By default, the code in this panel is prefixed with the contents of the answer box, giving you an easy way to test your answer.</p>
<p>You can uncheck the 'Prefix with answer' checkbox to run the code in this panel standalone, e.g. to explore how small code fragments behave.</p>";s:34:"scratchpadui_scratchpad_name_descr";s:68:"Display name of the scratchpad, used to hide/un-hide the scratchpad.";s:30:"scratchpadui_button_name_descr";s:16:"Run button text.";s:30:"scratchpadui_prefix_name_descr";s:40:"Prefix with answer check-box label text.";s:27:"scratchpadui_run_lang_descr";s:129:"Language used to run code when the run button is clicked, this should be the language your wrapper is written in (if applicable).";s:25:"scratchpadui_params_descr";s:38:"Parameters for the sandbox webservice.";s:38:"scratchpadui_output_display_mode_descr";s:1502:"Control how program output is displayed on runs, there are three modes:
    <ul>
        <li>text: Display the output as text, html escaped. (default)</li>
        <li>json: Display programs that output JSON, useful for capturing stdin and displaying images. (recommended)</li>
        <ul>
            <li>Accepts JSON in run output with the fields:</li>
            <ul>
                <li>returncode: Exit code from program run.</li>
                <li>stdout: Stdout text from program run.</li>
                <li>stderr: Error text from program run.</li>
                <li>files: An object containing filenames mapped to base64 encoded images. These will be displayed below any stdout text.</li>
            </ul>
           <li>When the returncode is set to 42, an HTML input field will be added after the last stdout received. When the enter key is pressed inside the input, the input's value is added to stdin and the program is run again with this updated stdin. This is repeated until returncode is not set to 42. </li></ul>
        <li>html: Display program output as raw html inside the output area. (advanced)</li>
            <ul>
                <li>This can be used to show images and insert other HTML.</li>
                <li>Giving an &lt;input&gt; element the class coderunner-run-input will add an event: when the enter key is pressed inside the input, the input's value is added to stdin and the program is run again with this updated stdin.</li>
            </ul>
    </ul>";s:33:"scratchpadui_open_delimiter_descr";s:127:"The opening delimiter to use when inserting answer or Scratchpad code into the wrapper. It will replace the default value '{|'.";s:34:"scratchpadui_close_delimiter_descr";s:127:"The closing delimiter to use when inserting answer or Scratchpad code into the wrapper. It will replace the default value '|}'.";s:28:"scratchpadui_help_text_descr";s:22:"The help text to show.";s:30:"scratchpadui_wrapper_src_descr";s:168:"The location of wrapper to be used by the run button: setting to 'globalextra' will use text in global extra field, 'prototypeextra' will use the prototype extra field.";s:37:"scratchpadui_disable_scratchpad_descr";s:83:"Disable the scratchpad, effectively revert back to Ace UI from student perspective.";s:32:"scratchpadui_invert_prefix_descr";s:127:"Inverts meaning of prefix_ans serialisation: '1' means un-ticked -- and vice versa. This can be used to swap the default state.";s:25:"scratchpadui_escape_descr";s:191:"Escape (JSON with " removed from start and end) ANSWER_CODE and SCRATCHPAD_CODE before insertion into wrapper. Useful when inserting code into a string. NOTE: single quotes ' are NOT escaped.";s:31:"scratchpadui_jobe_servers_descr";s:169:"A list of Jobe servers, one of which will be randomly selected as a direct target for AJAX requests, rather than going via Moodle. EXPERIMENTAL and potentially insecure.";s:27:"scratchpadui_api_keys_descr";s:128:"A list of API keys to use with the jobe_servers (if given). If empty, no API key is used. EXPERIMENTAL and potentially insecure.";s:30:"scratchpad_ui_badrunwrappersrc";s:65:"Invalid run wrapper source given, please contact question author.";s:26:"scratchpad_ui_bad_api_keys";s:88:"Misconfigured scratchpad-direct. API key list length must equal jobe server list length.";s:19:"scratchpad_ui_error";s:47:"XML HTTP request failed. Network error or CORS.";s:34:"scratchpad_ui_invalidserialisation";s:72:"Invalid JSON serialisation provided, must include \"answer_code\" field.";s:25:"scratchpad_ui_no_protocol";s:53:"jobe server name must start with http:// or https://.";s:28:"scratchpad_ui_request_failed";s:33:"Request to sandbox server failed.";s:30:"scratchpad_ui_templateloadfail";s:95:"Scratchpad UI template failed to load, please refresh the page. If this persists please report.";s:22:"tableui_num_rows_descr";s:105:"The (initial) number of rows in the table, excluding the top header row (if headers are given). Required.";s:25:"tableui_num_columns_descr";s:105:"The number of columns in the table, excluding the left-most label column (if labels are given). Required.";s:28:"tableui_column_headers_descr";s:41:"A list of strings for the column headers.";s:26:"tableui_dynamic_rows_descr";s:82:"If true, and "Add row" button is provided to allow users to add rows to the table.";s:24:"tableui_row_labels_descr";s:66:"A list of strings for the row labels, i.e. the values in column 0.";s:26:"tableui_locked_cells_descr";s:164:"A list of 2-element lists giving the 0-origin coordinates of cells that the user cannot alter. Coordinates do not include a possible header row or row-label column.";s:35:"tableui_column_width_percents_descr";s:154:"A list of floating point numbers giving the percentage of the available table width to allocate to the columns, including the row-label column if present.";s:28:"tableui_lines_per_cell_descr";s:45:"The number of text rows in each textarea/cell";s:32:"tableui_sync_interval_secs_descr";s:123:"The time interval in seconds between calls to sync the UI contents back to the question answer. 0 for no such auto-syncing.";s:20:"table_ui_invalidjson";s:37:"Table UI: invalid JSON serialisation.";s:29:"table_ui_invalidserialisation";s:32:"Table UI: invalid serialisation.";s:22:"table_ui_missingparams";s:51:"Table UI needs parameters num_columns and
num_rows.";s:8:"template";s:8:"Template";s:16:"template_changed";s:77:"Per-test template changed - disable combinator? ['Cancel' leaves it enabled.]";s:16:"templatecontrols";s:17:"Template controls";s:21:"templatecontrols_help";s:2296:"Checking the 'Is combinator' checkbox
specifies that the template is a combinator template, which combines (or attempts
to combine) the student answer plus all test cases into a single run. If this
checkbox is checked, you will also need to define the value of the test_splitter_re
field, which is the PHP regular expression used to split the output from the
program run back into a set of individual test runs. However, you do not need
to define this if you're also using a template grader, as in that case the
template code is responsible for splitting the output itself, and grading it.

Combinator templates do not get passed a TEST Twig variable. Instead they
receive a variable TESTCASES, which is a list of all the tests in the
question. The program produced by the template is generally assumed to combine the
STUDENT_ANSWER and all the TESTCASES into a single program which, when it is run,
outputs the test results from each test case, separated by a unique string.
The separator string is defined by a regular expression given by the form
field 'test_splitter_re' below.

However, if testcases have standard input defined, combinator templates become
problematic. If the template constructs a single program, what should the standard
input be? The simplest (and default) solution is to
run the test cases one at a time, using the combinator template to build
each program, passing it a TESTCASES variable containing just a single test.
This 'trick' allows the combinator template to serve a dual role: it behaves
as a per-test-case template (with a 1-element TESTCASES array) when the question
author supplies standard input but as a proper combinator (with an n-element
TESTCASES array) otherwise. To change this behaviour so that the combinator
receives all testcases, even when stdin is present, check the 'Allow multiple
stdins' checkbox.

If a run of the combinator program results in any output to stderr, that
is interpreted as a run error. To ensure the student gets credit for as many
valid tests as possible, the system behaves as it does when standard input
is present, falling back to running each test separately. This does not
apply to combinator graders, however, which are required to deal with all
runtime errors themselves and must always return a valid JSON outcome.";s:13:"templateerror";s:14:"TEMPLATE ERROR";s:14:"templategrader";s:15:"Template grader";s:13:"template_help";s:1922:"The template defines the program(s) that run in the sandbox for a given
student answer and test(s). There are two
types of template:

* a per-test template, which defines a program to be run for a single test case and,
* a 'combinator' template which defines a program that combines all the different cases into a single program.

The 'is_combinator' checkbox is left unchecked for a per-test template and is
set checked for a combinator template. The rest of this help panel assumes you
are using a per-test template; see the full documentation for the use of
combinator templates.

The template is processed
by the Twig template engine (see http://twig.sensiolabs.org)
in a context in which STUDENT_ANSWER is the student's
response and TEST.testcode is the code for the current testcase. These values
(and other testcase values like TEST.expected, TEST.stdin, TEST.mark)
can be inserted into the template by enclosing them in double braces, e.g.
<code>{{TEST.testcode}}</code>. For use within literal strings, an appropriate escape
function should be applied, e.g. <code>{{STUDENT_ANSWER | e('py')}}</code> is
suitable for use within Python triple-double-quoted
strings. Other escape functions are <code>e('c')</code>, <code>e('java')</code>,
<code>e('matlab')</code>. The program that is output by Twig is then compiled and executed
with the language of the selected built-in type and with stdin set
to TEST.stdin. Output from that program is then passed to the selected grader.
See the help under 'Grading controls' for more on that.

Note that if a customised per-test template is used
there will be a compile-and-execute job submitted to the sandbox for every test case,
whereas most built-in question types define instead a combinator template that combines
all test cases into a single run.

If the template-debugging checkbox is clicked, the program generated
for each sandbox run will be displayed in the output.";s:14:"templateparams";s:15:"Template params";s:24:"templateparamsevalpertry";s:20:"Evaluate per student";s:18:"templateparamslang";s:12:"Preprocessor";s:26:"templateparamsusingsandbox";s:283:"Preprocessors other than Twig use
the sandbox server. If "Evaluate per student" is also set, then when a student
starts a quiz all such questions initiate
a sandbox run before the question can even be displayed. In a test or exam,
this can overload the sandbox server. Caveat emptor!";s:19:"templateparams_help";s:1203:"If non-blank, the template parameters field must
evaluate to a JSON-format record. In its simplest form the field <i>is</i> just a JSON
record defining a set of variables that are added to the environment for the Twig
template engine when it expands the template (and other fields if Twig All is set).

If a preprocessor is specified in the Template param controls section,
the template parameters are first processed by the specified language
to yield a JSON record. See <a href="https://coderunner.org.nz/mod/url/view.php?id=199">
the documentation</a> for details.

<b>Warning:</b> use of a preprocessor other than Twig can have drastic performance
implications if the Evaluate-per-student checkbox is
checked, which it has to be if used for randomisation or for per-student question
customisation. Preprocessing must be done before a question
can be displayed to a student and, except for Twig, takes place on the Jobe sandbox
server. Every attempt on every question of this sort by every student will result in a job
being sent to that server. This can result in thousands of jobs hitting the
Jobe server at once at the start of a large test or exam, which will probably
overload it. Caveat Emptor!";s:12:"testalltitle";s:34:"Test all questions in this context";s:17:"testallincategory";s:35:"Test all questions in this category";s:8:"testcase";s:14:"Test case {$a}";s:16:"testcasecontrols";s:16:"Test properties:";s:21:"testcasecontrols_help";s:608:"If 'Use as example' is checked, this test will be automatically included in the
question's 'For example:' results table.

The 'Display' combobox determines when this testcase is shown to the student
in the results table.

If 'Hide rest if fail' is checked and this test fails, all subsequent tests will
be hidden from the student, regardless of the setting of the 'Display' combobox.

'Mark' sets the value of this test case; meaningful only if this is not an
'All-or-nothing' question.

'Ordering' can be used to change the order of testcases when the question is
saved: testcases are ordered by this field.";s:9:"testcases";s:10:"Test cases";s:8:"testcode";s:9:"Test code";s:10:"testcolhdr";s:4:"Test";s:15:"testingquestion";s:21:"Testing question {$a}";s:14:"testsplitterre";s:21:"Test splitter (regex)";s:13:"testcode_help";s:64:"The code for the test, seen by the template as {{TEST.testcode}}";s:8:"testtype";s:18:"Precheck test type";s:13:"testtype_help";s:243:"If Prechecking is enabled and set to 'selected', this setting controls whether
the test is used only with a normal run, only with a precheck run or in both runs.
If Prechecking is set to anything other than 'selected', this setting is
ignored.";s:15:"testtype_normal";s:10:"Check only";s:17:"testtype_precheck";s:13:"Precheck only";s:13:"testtype_both";s:4:"Both";s:11:"toobigfiles";s:23:"Oversized file(s): {$a}";s:8:"tooshort";s:73:"Answer is too short to be meaningful and has been ignored without penalty";s:7:"twigall";s:8:"Twig all";s:12:"twigcontrols";s:23:"Template param controls";s:17:"twigcontrols_help";s:2082:"Template parameters were traditionally referred to during Twig expansion in the form
{{QUESTION.parameters.someparam}} However, if the Hoist Template Parameters
checkbox is checked, the parameters are hoisted into the Twig global name space
and can be referenced simply as {{someparam}}.

Ace/Scratchpad compliance allows seamless switching between the Ace and
Scratchpad UIs. Leave checked unless you wish Ace to be able to edit a JSON string
with an "answer_code" key, which would be taken to be a Scratchpad serialisation.

If Twig All is checked, Twig macro expansion is applied to the
question text, sample answer, answer preload, UI parameters and all test case fields
using the template parameters as an environment. You will usually
need to turn on TwigAll if using randomisation within the template parameters.
Note that this Twig All expansion occurs when the question is first initialised, whereas
the Twig expansion of the template occurs much later, when the student submits
an answer. The environment for expanding the template includes the QUESTION
Twig variable (a subset of the entire question record), some fields of which
might have been expanded as a result of using Twig All.

The text in the template parameters field must either be JSON or must evaluate
to yield JSON when processed by the specified Preprocessor. Be warned that choosing
a preprocessor other than Twig results in a submission to the Jobe sandbox before
the question can even be displayed. See <a href="https://coderunner.org.nz/mod/url/view.php?id=199">
the documentation</a> for how to write a non-Twig preprocessor.

If using a preprocessor other than Twig, a Jobe sandbox submission is usually
required for each question for each student when they start the quiz.
If <i>Evaluate per student</i> is unchecked a single sandbox submission will
take place only when the question is saved; this is a relatively low-cost operation but
is not normally useful, as it essentially prevents
any use of per-student randomisation. It can however be used to generate
question content in some situations.";s:9:"twigerror";s:15:"Twig error {$a}";s:15:"twigerrorintest";s:41:"Twig error when processing this test {$a}";s:11:"type_header";s:24:"CodeRunner question type";s:8:"typename";s:13:"Question type";s:12:"typerequired";s:58:"Please select the type of question (language, format, etc)";s:9:"uichanged";s:82:"UI changed. Save and reload page to see and edit available ui parameters (if any).";s:10:"uicontrols";s:9:"Input UIs";s:15:"uicontrols_help";s:1581:"Select the User Interface controllers for the student answer and
the question author's template.

The Student Answer dropdown displays a list
of available plugins. For coding questions, the Ace editor is usually used.
A value of 'None' can be used to provide just a raw text box.

The value
'Graph' provides the user with a simple graph-drawing user-interface for use
with questions that ask the student to draw a graph to some specification; such
questions will usually have a single test case, graded with a template
that analyses the serialised
representation of the graph and prints a message like "OK" if the answer is
correct or a suitably informative error message otherwise.

The 'Table' user interface element, which displays a table of text
areas for the student to
fill in. It is used by the 'python3_program_testing' question type, which is
included in the sample questions on github.

The 'Gapfiller' and 'Html' user interfaces are documented in the
main CodeRunner documentation at https://github.com/trampgeek/moodle-qtype_coderunner#code-runner.

Students with poor eyesight, or authors wishing to inspect serialisations
(say to understand the representation used by the Graph UI),
can toggle the use of all UI plugins on the current page by typing
Ctrl-Alt-M.

Whatever value is selected for the student answer will also be used within
the editor form for the Sample Answer and the Answer Preload fields.

If 'Template uses ace' is checked,
the Ace code editor will manage both the template and the template parameters
boxes. Otherwise a raw text box will be used.";s:11:"ui_fallback";s:30:"Falling back to raw text area.";s:16:"uiparametergroup";s:13:"UI parameters";s:21:"uiparametergroup_help";s:217:"A JSON string defining any User Interface
parameter values that are either required by the UI plugin or which override the
default values. For example, to draw larger nodes when using the GraphUI: '{"noderadius": 30}'";s:12:"uiparameters";s:20:"UI parameters (JSON)";s:20:"uiparametertablehead";s:52:"The {$a->uiname} UI takes the following parameters: ";s:11:"uiparamname";s:4:"Name";s:11:"uiparamdesc";s:11:"Description";s:14:"uiparamdefault";s:7:"Default";s:20:"unauthorisedbulktest";s:59:"You do not have suitable access to any CodeRunner questions";s:20:"unauthoriseddbaccess";s:41:"You are not authorised to use this script";s:12:"unknownerror";s:73:"An unexpected error occurred. The sandbox may be down. Try again shortly.";s:28:"unknowncombinatorgraderfield";s:64:"Unknown field name ({$a->fieldname}) in combinator grader output";s:15:"unknownuiplugin";s:66:"Information on an unknown plugin ({$a->pluginname}) was requested.";s:17:"unserializefailed";s:69:"Stored test results could not be deserialised. Perhaps try regrading?";s:12:"useasexample";s:14:"Use as example";s:6:"useace";s:17:"Template uses ace";s:14:"validateonsave";s:16:"Validate on save";s:20:"wrongnumberofformats";s:83:"Wrong number of test results column formats. Expected {$a->expected}, got {$a->got}";s:9:"wsbadjson";s:63:"Params and file parameters must be blank or a valid JSON record";s:15:"wscputimeexcess";s:47:"CPU time specified exceeds set maximum CPU time";s:10:"wsdisabled";s:48:"Sandbox web service disabled. Talk to a sysadmin";s:15:"wsloggingenable";s:29:"Log sandbox web service usage";s:20:"wsloggingenable_desc";s:155:"If this option is checked, every code execution via the sandbox web service will be logged. This option must be enabled if user rate throttling is to work.";s:12:"wsmaxcputime";s:19:"Max CPU time (secs)";s:17:"wsmaxcputime_desc";s:118:"Limits the maximum CPU time that a web service job can use, even if it explicitly sets the CPU time sandbox parameter.";s:15:"wsmaxhourlyrate";s:30:"Max hourly rate of submissions";s:20:"wsmaxhourlyrate_desc";s:135:"If a user attempts to exceed this rate of submissions in any given hour their submissions will be disallowed. 0 for no rate throttling.";s:10:"wsnoaccess";s:60:"Only logged-in non-guest users can access this functionality";s:12:"wsnolanguage";s:28:"Language "{$a}" is not known";s:24:"wssubmissionrateexceeded";s:79:"You have exceeded the maximum hourly 'Try it!' submission rate. Request denied.";s:24:"xmlcoderunnerformaterror";s:39:"XML format error in coderunner question";s:16:"enablegradecache";s:80:"Enable reading/writing of job,result pairs from/to the Coderunner grading cache.";s:24:"coderunner_grading_cache";s:62:"Caches grading results so we can avoid going to Jobe so often.";s:33:"cachedef_coderunner_grading_cache";s:62:"Caches grading results so we can avoid going to Jobe so often.";s:21:"enablegradecache_desc";s:790:"Experimental. Currently only recommended with a file store backend but should work with Redis (just check that Redis is using persistence so that it doesn't blow up your memeory)!<br>The cache is a local Moodle cache to store results of grading questions. Mainly to speed up regrading by using cached results for jobe runs where the same jobe submission has already been graded. Currently WS jobs (eg, try-it boxes and scratchpad runs) will never be cached.<br>NOTES: If you turn off grade caching then it is usually good to empty the Coderunner grade cache before you turn it on again so you have a known state for the cache. You should also clear the cache if you change the Jobe back-end (eg, installing a new version of Python there) as results may now differ from what is in the cache.";s:19:"backtobulktestindex";s:36:"Go back to the bulk test index page.";s:21:"retestfailedquestions";s:24:"Re-test failed questions";s:32:"cachepurgecheckingkeyxoftotalnum";s:75:"Procesing key {$a->x} of {$a->totalnumkeys} keys in total (for all courses)";s:30:"gradingcachedefinitionnotfound";s:68:"Strange... the Coderunner grading cache definition cannot be found!?";s:29:"gradingcachefilestorenotfound";s:68:"Strange... the Coderunner grading cache file store cannot be found!?";s:21:"purgingallkeysmessage";s:63:"Purging all keys for context, regardless of Time to Live (TTL).";s:21:"purgingoldkeysmessage";s:101:"Purging only old keys for course, based on Time to Live. TTL={$a->seconds} seconds (={$a->days} days)";s:23:"purgeoldcachekeysbutton";s:19:"Purge only OLD keys";s:23:"purgeallcachekeysbutton";s:14:"Purge ALL keys";s:20:"cachepurgeindextitle";s:28:"Coderunner Cache Purge Index";s:19:"cachepurgepagetitle";s:22:"Purging cache for {$a}";s:19:"cachepurgeindexinfo";s:241:"Purging OLD keys will only delete cache entries for grading runs that are older than the Coderunner cache Time To Live (TTL) as set in the .../coderunner/db/caches.php file.<br>Purging ALL will delete all cache entries for the given context.";s:14:"currentttlinfo";s:104:"Coderunner grading cache Time to Live is currently set to TTL = {$a->seconds} seconds (={$a->days} days)";s:18:"noquestionstopurge";s:64:"None of the contexts you have access to have any cached results.";s:38:"contextidnotacourseincachepurgerequest";s:58:"Grade cache not purged as context_id {$a} is not a course.";s:28:"purgeoldcacheentriestaskname";s:52:"Purge Old Coderunner File Store Cache Entries - task";s:20:"bulktestnumrunslabel";s:29:"Number of runs per question: ";s:26:"bulktestnumrunsexplanation";s:122:"How many times each included question will be tested. Repeatitions will depend on <emph>Repeat random only</emph> setting.";s:23:"bulktestrandomseedlabel";s:13:"Random seed: ";s:29:"bulktestrandomseedexplanation";s:835:"If set to a postive integer then the PHP randomseed is set to this value before running the test(s) for each question that has <emph>random</emph> in its name.<br>
If you don't set the random seed then each time you do a bulk test you will get random sequences of question instances, which may mean the grade cache isn't so useful and more questions have to actually be run on the Jobe server (depending on how random your questions are).<br>
For a given seed the sequence of random question instances should be the same (assuming your question template uses the random seed it is given correctly).
Setting the random seed allows you to recreate a specific sequences of random question instances (eg, you could do 100 runs with 1 being
the initial seed, then try 100 runs with 200 being the seed, etc, hopefully getting more coverage).";s:29:"bulktestrepeatrandomonlylabel";s:20:"Repeat random only: ";s:35:"bulktestrepeatrandomonlyexplanation";s:74:"Limits repeated runs to questions with <emph>random</emph> in their names.";s:28:"bulktestclearcachefirstlabel";s:34:"Clear course grading cache first: ";s:34:"bulktestclearcachefirstexplanation";s:285:"This will clear the whole grading cache for the course being tested. Be careful as you will lose the whole grading cache for all student attempts on all questions in the course! This option is useful when jobe servers are being changed/updated, ie, to ensure new results are generated.";s:21:"bulktestusecachelabel";s:19:"Use grading cache: ";s:27:"bulktestusecacheexplanation";s:323:"Whether or not to use the Coderunner grading cache. Turning it off means that questions will always be run on the
jobe server. When doing multiple runs, this setting will help show issues with individual jobe servers when you are using a list of servers or a jobe proxy that is load sharing to multiple jobes. Deafult: true";s:33:"bulktestallcachenotclearedmessage";s:127:"<b>Note:</b> Grading cache not cleared -- do it from admin-plugins-cache if you really want to clear the cache for all courses!";}